{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision fastai datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Jan  8 2020, 19:59:22) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "# get the python version\n",
    "import sys\n",
    "print(sys.version)\n",
    "is_38 = sys.version_info >= (3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "# import visiondataset\n",
    "from torchvision.datasets import VisionDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyDataset(VisionDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = \".\",\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "        normalize: Tuple[float, float] = None,\n",
    "    ) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.labels = [ 'tg', 'Ng', 'Pci', 'H', 'Wp', 'Ph', 'Ox', 'Ow', 'Hbt', 'Wm', 'Wr' ]\n",
    "        self.ids, self.data, self.features = self._load_data(root, ij=normalize)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        # id, img, features = self.ids[index], self.data[index], self.features.iloc[index]\n",
    "        img, features = self.data[index], torch.Tensor(self.features.iloc[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        # img = Image.fromarray(img.numpy().astype(np.uint8))\n",
    "        \n",
    "\n",
    "        img = img.reshape(pixels, pixels)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        img = img.reshape(pixels**2, -1)\n",
    "\n",
    "        return img, features\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _load_data(self, root: str, ij: Tuple[float, float]):\n",
    "        ids = pd.read_csv(f'{root}/PD_ids_train.csv')\n",
    "        data = pd.read_csv(f'{root}/PD_imgs_np_train.csv')\n",
    "        features = pd.read_csv(f'{root}/PD_conditions_train.csv')\n",
    "\n",
    "        # convert all to list\n",
    "        # TODO something better than a list\n",
    "        ids = ids.values.tolist()\n",
    "        data = data.values.tolist()\n",
    "        features = features.values.tolist()\n",
    "\n",
    "        # resize the data now\n",
    "        # TODO hmmmm\n",
    "        data = torch.Tensor(data)\n",
    "        # TODO the first byte is bad\n",
    "        # remove the first column\n",
    "        data = data[:, 1:]\n",
    "        # data = data.reshape(len(data), 140, 39).float()\n",
    "        # TODO do this properly\n",
    "\n",
    "        # add 16 bytes of padding\n",
    "        # data = F.pad(data, (0, 16), value=0)\n",
    "        # data = data.reshape(len(data), 74, 74).float()\n",
    "        # print(data.shape)\n",
    "        # # upscale to 128x128\n",
    "        data = data.reshape(len(data), 140, 39).float()\n",
    "        # data = F.interpolate(data.unsqueeze(1), size=(128, 128), mode='nearest').squeeze(1)\n",
    "        # data = F.interpolate(data.unsqueeze(1), size=(128, 39), mode='nearest').squeeze(1)\n",
    "        # data = F.pad(data, (0, 128-39), value=0)\n",
    "        # data = F.pad(data, (0, 64-39), value=0)\n",
    "        # data = F.interpolate(data.unsqueeze(1), size=(140, 39*3), mode='nearest').squeeze(1)\n",
    "        # data = F.interpolate(data.unsqueeze(1), size=(64, 64), mode='nearest').squeeze(1)\n",
    "        # batch x pixels x pixels\n",
    "        data = F.pad(data, (0, pixels-39, 0, pixels-140), value=0)\n",
    "        print(data.shape)\n",
    "        # repeat every pixel 3 times along the width\n",
    "        \"\"\"\n",
    "        [1, 2, 3] => [1, 1, 1, 2, 2, 2, 3, 3, 3]\n",
    "        \"\"\"\n",
    "        # data = data.repeat_interleave(3, dim=2)\n",
    "        # print the first row of the first image\n",
    "\n",
    "\n",
    "        data = 2 * (data / 255) - 1\n",
    "        # print(data.shape)\n",
    "        # print(data[0, 5, :])\n",
    "\n",
    "        # 140x39 => 140*39=2^n^2 => sqrt(140*39) = 2^n => 73.8918128076 = 2^n => log2(ceil(73.8918128076)) = n => ceil(6.2094533656) = n\n",
    "        # -_- i dont want nearest base2, but nearest square\n",
    "        # 140*39 => ceil(sqrt(140*39)) = 74\n",
    "        # way less fun, but better\n",
    "        # 140*39 - 74*74 = 16B of padding\n",
    "\n",
    "        # data = F.interpolate(data.unsqueeze(1), size=(128, 39), mode='nearest').squeeze(1)\n",
    "        # TODO what\n",
    "        data = data.reshape(len(data), -1)\n",
    "        # data = F.pad(data, (0, 4), value=-1)\n",
    "\n",
    "        # NOTE convert features to dtype f32 for mps\n",
    "        features = pd.DataFrame(features, columns=self.labels).astype('float32')\n",
    "\n",
    "        if ij is not None:\n",
    "            # drop fields that are not used\n",
    "            features = features.drop(columns=['H', 'Wp', 'Wm', 'Wr'])\n",
    "\n",
    "            # NOTE: (-1, 1) => y = 2 * (x - min) / (max - min) - 1\n",
    "            #       ( i, j) => y = (j-i) * (x - min) / (max - min) + i\n",
    "            features = (ij[1] - ij[0]) * (features - features.min()) / (features.max() - features.min()) + ij[0]\n",
    "            # NOTE: they are nan because the min and max are the same, std is 0 (and mean is normally NaN); so we can just set them to 0\n",
    "            features = features.fillna(0)\n",
    "\n",
    "        return ids, data, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why the Fancy Normalization Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([668, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(root='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tg</th>\n",
       "      <th>Ng</th>\n",
       "      <th>Pci</th>\n",
       "      <th>H</th>\n",
       "      <th>Wp</th>\n",
       "      <th>Ph</th>\n",
       "      <th>Ox</th>\n",
       "      <th>Ow</th>\n",
       "      <th>Hbt</th>\n",
       "      <th>Wm</th>\n",
       "      <th>Wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>6.680000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>333.500000</td>\n",
       "      <td>68.757767</td>\n",
       "      <td>38.844311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>327.544922</td>\n",
       "      <td>25.612276</td>\n",
       "      <td>5.974551</td>\n",
       "      <td>1456.753296</td>\n",
       "      <td>12.200080</td>\n",
       "      <td>3.087517e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>192.978683</td>\n",
       "      <td>52.810455</td>\n",
       "      <td>61.393684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.626938</td>\n",
       "      <td>3.267343</td>\n",
       "      <td>2.021089</td>\n",
       "      <td>20.019684</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.282210e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1410.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>3.087504e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1485.000000</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>3.087504e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sum</td>\n",
       "      <td>222778.000000</td>\n",
       "      <td>45930.199219</td>\n",
       "      <td>25948.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218800.000000</td>\n",
       "      <td>17109.000000</td>\n",
       "      <td>3991.000000</td>\n",
       "      <td>973106.937500</td>\n",
       "      <td>8149.598633</td>\n",
       "      <td>2.062453e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             tg            Ng           Pci      H     Wp  \\\n",
       "0  count     668.000000    668.000000    668.000000  668.0  668.0   \n",
       "1   mean     333.500000     68.757767     38.844311    0.0    0.0   \n",
       "2    std     192.978683     52.810455     61.393684    0.0    0.0   \n",
       "3    min       0.000000      0.000000      0.000000    0.0    0.0   \n",
       "4    max     667.000000    200.000000    200.000000    0.0    0.0   \n",
       "5    sum  222778.000000  45930.199219  25948.000000    0.0    0.0   \n",
       "\n",
       "              Ph            Ox           Ow            Hbt           Wm  \\\n",
       "0     668.000000    668.000000   668.000000     668.000000   668.000000   \n",
       "1     327.544922     25.612276     5.974551    1456.753296    12.200080   \n",
       "2      61.626938      3.267343     2.021089      20.019684     0.000080   \n",
       "3     300.000000     21.000000     3.000000    1410.000000    12.200000   \n",
       "4     500.000000     30.000000     9.000000    1485.000000    12.200000   \n",
       "5  218800.000000  17109.000000  3991.000000  973106.937500  8149.598633   \n",
       "\n",
       "             Wr  \n",
       "0  6.680000e+02  \n",
       "1  3.087517e+05  \n",
       "2  1.282210e+00  \n",
       "3  3.087504e+05  \n",
       "4  3.087504e+05  \n",
       "5  2.062453e+08  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the count, mean, std, min, max, and sum of each column\n",
    "df_aggregated = dataset.features.agg(['count', 'mean', 'std', 'min', 'max', 'sum']).reset_index()\n",
    "display(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tg</th>\n",
       "      <th>Ng</th>\n",
       "      <th>Pci</th>\n",
       "      <th>H</th>\n",
       "      <th>Wp</th>\n",
       "      <th>Ph</th>\n",
       "      <th>Ox</th>\n",
       "      <th>Ow</th>\n",
       "      <th>Hbt</th>\n",
       "      <th>Wm</th>\n",
       "      <th>Wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.728170</td>\n",
       "      <td>1.538374</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798372</td>\n",
       "      <td>-0.493452</td>\n",
       "      <td>1.002157</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.722988</td>\n",
       "      <td>0.970305</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798372</td>\n",
       "      <td>1.342903</td>\n",
       "      <td>-1.471756</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.717806</td>\n",
       "      <td>-1.301973</td>\n",
       "      <td>0.507474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>0.424726</td>\n",
       "      <td>-0.482191</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.712624</td>\n",
       "      <td>-1.301973</td>\n",
       "      <td>1.810539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>1.342903</td>\n",
       "      <td>1.496940</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.707443</td>\n",
       "      <td>1.538374</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>1.342903</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1.707443</td>\n",
       "      <td>-0.584312</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798372</td>\n",
       "      <td>0.424726</td>\n",
       "      <td>-0.482191</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1.712624</td>\n",
       "      <td>-0.923260</td>\n",
       "      <td>-0.144059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>-1.411629</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1.717806</td>\n",
       "      <td>-0.582418</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>0.424726</td>\n",
       "      <td>-0.976974</td>\n",
       "      <td>-2.335366</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1.722988</td>\n",
       "      <td>0.591592</td>\n",
       "      <td>1.810539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>1.342903</td>\n",
       "      <td>1.002157</td>\n",
       "      <td>0.152188</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1.728170</td>\n",
       "      <td>0.970305</td>\n",
       "      <td>-0.632709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446962</td>\n",
       "      <td>1.342903</td>\n",
       "      <td>-0.482191</td>\n",
       "      <td>1.410947</td>\n",
       "      <td>-0.999251</td>\n",
       "      <td>-0.999251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tg        Ng       Pci   H  Wp        Ph        Ox        Ow  \\\n",
       "0   -1.728170  1.538374 -0.632709 NaN NaN  2.798372 -0.493452  1.002157   \n",
       "1   -1.722988  0.970305 -0.632709 NaN NaN  2.798372  1.342903 -1.471756   \n",
       "2   -1.717806 -1.301973  0.507474 NaN NaN -0.446962  0.424726 -0.482191   \n",
       "3   -1.712624 -1.301973  1.810539 NaN NaN -0.446962  1.342903  1.496940   \n",
       "4   -1.707443  1.538374 -0.632709 NaN NaN -0.446962  1.342903  0.012592   \n",
       "..        ...       ...       ...  ..  ..       ...       ...       ...   \n",
       "663  1.707443 -0.584312 -0.632709 NaN NaN  2.798372  0.424726 -0.482191   \n",
       "664  1.712624 -0.923260 -0.144059 NaN NaN -0.446962 -1.411629  0.012592   \n",
       "665  1.717806 -0.582418 -0.632709 NaN NaN -0.446962  0.424726 -0.976974   \n",
       "666  1.722988  0.591592  1.810539 NaN NaN -0.446962  1.342903  1.002157   \n",
       "667  1.728170  0.970305 -0.632709 NaN NaN -0.446962  1.342903 -0.482191   \n",
       "\n",
       "          Hbt        Wm        Wr  \n",
       "0    0.152188 -0.999251 -0.999251  \n",
       "1    0.152188 -0.999251 -0.999251  \n",
       "2    0.152188 -0.999251 -0.999251  \n",
       "3    0.152188 -0.999251 -0.999251  \n",
       "4    0.152188 -0.999251 -0.999251  \n",
       "..        ...       ...       ...  \n",
       "663  0.152188 -0.999251 -0.999251  \n",
       "664  0.152188 -0.999251 -0.999251  \n",
       "665 -2.335366 -0.999251 -0.999251  \n",
       "666  0.152188 -0.999251 -0.999251  \n",
       "667  1.410947 -0.999251 -0.999251  \n",
       "\n",
       "[668 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tg</th>\n",
       "      <th>Ng</th>\n",
       "      <th>Pci</th>\n",
       "      <th>H</th>\n",
       "      <th>Wp</th>\n",
       "      <th>Ph</th>\n",
       "      <th>Ox</th>\n",
       "      <th>Ow</th>\n",
       "      <th>Hbt</th>\n",
       "      <th>Wm</th>\n",
       "      <th>Wr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>6.666665e-01</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.997002</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.994003</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-3.333334e-01</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.991005</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.988006</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.960464e-08</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.988006</td>\n",
       "      <td>-0.621</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-3.333334e-01</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.991004</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-5.960464e-08</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.994003</td>\n",
       "      <td>-0.620</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-6.666667e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.997002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.666665e-01</td>\n",
       "      <td>0.328001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.333334e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tg     Ng  Pci   H  Wp   Ph        Ox            Ow       Hbt  Wm  \\\n",
       "0   -1.000000  0.500 -1.0 NaN NaN  1.0 -0.333333  6.666665e-01  0.328001 NaN   \n",
       "1   -0.997002  0.200 -1.0 NaN NaN  1.0  1.000000 -1.000000e+00  0.328001 NaN   \n",
       "2   -0.994003 -1.000 -0.3 NaN NaN -1.0  0.333333 -3.333334e-01  0.328001 NaN   \n",
       "3   -0.991005 -1.000  0.5 NaN NaN -1.0  1.000000  1.000000e+00  0.328001 NaN   \n",
       "4   -0.988006  0.500 -1.0 NaN NaN -1.0  1.000000 -5.960464e-08  0.328001 NaN   \n",
       "..        ...    ...  ...  ..  ..  ...       ...           ...       ...  ..   \n",
       "663  0.988006 -0.621 -1.0 NaN NaN  1.0  0.333333 -3.333334e-01  0.328001 NaN   \n",
       "664  0.991004 -0.800 -0.7 NaN NaN -1.0 -1.000000 -5.960464e-08  0.328001 NaN   \n",
       "665  0.994003 -0.620 -1.0 NaN NaN -1.0  0.333333 -6.666667e-01 -1.000000 NaN   \n",
       "666  0.997002  0.000  0.5 NaN NaN -1.0  1.000000  6.666665e-01  0.328001 NaN   \n",
       "667  1.000000  0.200 -1.0 NaN NaN -1.0  1.000000 -3.333334e-01  1.000000 NaN   \n",
       "\n",
       "     Wr  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  \n",
       "..   ..  \n",
       "663 NaN  \n",
       "664 NaN  \n",
       "665 NaN  \n",
       "666 NaN  \n",
       "667 NaN  \n",
       "\n",
       "[668 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize each column\n",
    "df_normalized = (dataset.features - dataset.features.mean()) / dataset.features.std()\n",
    "display(df_normalized)\n",
    "\n",
    "# make the values between -1 and 1\n",
    "df_normalized = (dataset.features - dataset.features.mean()) / dataset.features.std()\n",
    "df_normalized = 2 * (df_normalized - df_normalized.min()) / (df_normalized.max() - df_normalized.min()) - 1\n",
    "display(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tg     668\n",
       "Ng      17\n",
       "Pci     18\n",
       "H        1\n",
       "Wp       1\n",
       "Ph       3\n",
       "Ox       6\n",
       "Ow       7\n",
       "Hbt      3\n",
       "Wm       1\n",
       "Wr       1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the unique values of eatch column in the dataset\n",
    "# df_unique = dataset.features.apply(lambda x: x.unique())\n",
    "# display(df_unique)\n",
    "# get the length of each unique value\n",
    "df_unique_len = dataset.features.apply(lambda x: len(x.unique()))\n",
    "display(df_unique_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([668, 256, 256])\n",
      "\n",
      "data: tensor([[ 1.],\n",
      "        [ 1.],\n",
      "        [ 1.],\n",
      "        ...,\n",
      "        [-1.],\n",
      "        [-1.],\n",
      "        [-1.]])\n",
      "features: tensor([-1.0000,  0.5000, -1.0000,  1.0000, -0.3333,  0.6667,  0.3280])\n",
      "\n",
      "(1, 256, 256)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tg</th>\n",
       "      <th>Ng</th>\n",
       "      <th>Pci</th>\n",
       "      <th>H</th>\n",
       "      <th>Ox</th>\n",
       "      <th>Ow</th>\n",
       "      <th>Hbt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.328001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tg   Ng  Pci    H        Ox        Ow       Hbt\n",
       "0 -1.0  0.5 -1.0  1.0 -0.333333  0.666667  0.328001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MyDataset(root='data', normalize=(-1, 1))\n",
    "datum = dataset[0]\n",
    "print(f\"\"\"\n",
    "data: {datum[0]}\n",
    "features: {datum[1]}\n",
    "\"\"\")\n",
    "\n",
    "# convert data to image plot\n",
    "# TODO first pixel is bad\n",
    "img = np.array(datum[0])\n",
    "# img = img.reshape(-1, 128, 128)\n",
    "# img = Image.fromarray((img * 255).astype(np.uint8)[0])\n",
    "# plt.imshow(img)\n",
    "# img2 = np.array(datum[0])\n",
    "# img2 = img2[:-16].reshape(140, 39)\n",
    "# plt.imshow(img2)\n",
    "\n",
    "# downscale to 74x74\n",
    "# remove the padding\n",
    "# img = img[:-4].reshape(-1, 140, 39*3)\n",
    "img = img.reshape(-1, pixels, pixels)\n",
    "# img = F.interpolate(torch.Tensor(img).unsqueeze(0), size=(140, 39), mode='nearest').squeeze(0).numpy()\n",
    "print(img.shape)\n",
    "img = Image.fromarray((img * 255).astype(np.uint8)[0])\n",
    "plt.imshow(img)\n",
    "\n",
    "# convert features to dataframe\n",
    "# TODO not correct, but ai guessed the labels, so its funny\n",
    "# Ng = Nitrogen, Pci = Pesticide, H = Humidity, Wp = Watering pattern, Ph = pH, 0x = 0x, 0w = 0w, Hbt = Habitat, Wm = Weed management, Wr = Weather\n",
    "labels = [ 'tg', 'Ng', 'Pci', 'H', 'Wp', 'Ph', 'Ox', 'Ow', 'Hbt', 'Wm', 'Wr' ]\n",
    "labels = [ 'tg', 'Ng', 'Pci', 'H', 'Ox', 'Ow', 'Hbt' ]\n",
    "conditions = np.array(datum[1])\n",
    "features = pd.DataFrame([conditions], columns=labels)\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tg</th>\n",
       "      <th>Ng</th>\n",
       "      <th>Pci</th>\n",
       "      <th>Ph</th>\n",
       "      <th>Ox</th>\n",
       "      <th>Ow</th>\n",
       "      <th>Hbt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>6.680000e+02</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>668.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>-1.766725e-08</td>\n",
       "      <td>-0.312423</td>\n",
       "      <td>-0.611557</td>\n",
       "      <td>-0.724551</td>\n",
       "      <td>0.024950</td>\n",
       "      <td>-0.008483</td>\n",
       "      <td>0.246589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>std</td>\n",
       "      <td>5.786485e-01</td>\n",
       "      <td>0.528105</td>\n",
       "      <td>0.613937</td>\n",
       "      <td>0.616267</td>\n",
       "      <td>0.726076</td>\n",
       "      <td>0.673697</td>\n",
       "      <td>0.533858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sum</td>\n",
       "      <td>-1.525879e-05</td>\n",
       "      <td>-208.697998</td>\n",
       "      <td>-408.519989</td>\n",
       "      <td>-484.000000</td>\n",
       "      <td>16.666679</td>\n",
       "      <td>-5.666660</td>\n",
       "      <td>164.720627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            tg          Ng         Pci          Ph          Ox  \\\n",
       "0  count  6.680000e+02  668.000000  668.000000  668.000000  668.000000   \n",
       "1   mean -1.766725e-08   -0.312423   -0.611557   -0.724551    0.024950   \n",
       "2    std  5.786485e-01    0.528105    0.613937    0.616267    0.726076   \n",
       "3    min -1.000000e+00   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "4    max  1.000000e+00    1.000000    1.000000    1.000000    1.000000   \n",
       "5    sum -1.525879e-05 -208.697998 -408.519989 -484.000000   16.666679   \n",
       "\n",
       "           Ow         Hbt  \n",
       "0  668.000000  668.000000  \n",
       "1   -0.008483    0.246589  \n",
       "2    0.673697    0.533858  \n",
       "3   -1.000000   -1.000000  \n",
       "4    1.000000    1.000000  \n",
       "5   -5.666660  164.720627  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the count, mean, std, min, max, and sum of each column\n",
    "df_aggregated = dataset.features.agg(['count', 'mean', 'std', 'min', 'max', 'sum']).reset_index()\n",
    "display(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a histogram of each column\n",
    "dataset.features.hist(figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 18832 bytes\n"
     ]
    }
   ],
   "source": [
    "# get the memory usage so far\n",
    "print(f\"Memory usage: {dataset.features.memory_usage().sum()} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "# import visiondataset\n",
    "from torchvision.datasets import VisionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.optim as optim \n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastai.vision.gan import *\n",
    "\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5460\n",
      "devices: 1\n",
      "device:  NVIDIA A30\n",
      "device0: _CudaDeviceProperties(name='NVIDIA A30', major=8, minor=0, total_memory=24049MB, multi_processor_count=56)\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "channels = 1 ## 1 for B&W, 3 for RGB, 4 for RGBA\n",
    "\n",
    "learning_rate    = 2e-4 #0.003  ## Adam default   ## 0.001 2e-4#\n",
    "batch_size       = 2\n",
    "N_Epochs         = 3000 #4_000  ##27000  \n",
    "num_classes = 1\n",
    "width = 39\n",
    "height = 140\n",
    "img_size = width*height*channels\n",
    "certainty_repeater = 6# channels**2 - num_classes\n",
    "\n",
    "print(f\"{img_size}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    # get number of cuda devices\n",
    "    print(f\"devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"device:  {torch.cuda.get_device_name()}\")\n",
    "    print(f\"device0: {torch.cuda.get_device_properties(0)}\")\n",
    "    print(f\"{torch.cuda.memory_summary()}\")\n",
    "elif torch.backends.mps is not None:\n",
    "    device = torch.device('mps')\n",
    "    print(f\"{torch.mps.current_allocated_memory()}\")\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    # print a warning that cpu is being used\n",
    "    print(\"Warning: Running on CPU. This will be slow.\")\n",
    "print(f\"{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset into a train / test split\n",
    "# TODO i dont think test is used\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.95, 0.05])\n",
    "\n",
    "# define the dataloader\n",
    "dl_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dl_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_GAN_losses(list_losses_critic, list_losses_generator):\n",
    "    the_epochs = [i for i in range(len(list_losses_critic))]  \n",
    "\n",
    "    plt.plot(the_epochs, list_losses_critic,      label = \"critic\") \n",
    "    plt.plot(the_epochs, list_losses_generator,  label = \"generator\")\n",
    "    plt.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    f1_measure = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    print('F1-mesure: %.3f' % f1_measure)\n",
    "    return f1_measure, confmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_per_epoch(the_scores_list):\n",
    "    x_epochs = []\n",
    "    y_epochs = [] \n",
    "    for i, val in enumerate(the_scores_list):\n",
    "        x_epochs.append(i)\n",
    "        y_epochs.append(val)\n",
    "    \n",
    "    plt.scatter(x_epochs, y_epochs,s=50,c='lightgreen', marker='s', label='score')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('score')\n",
    "    plt.title('Score per epoch')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_G_vector_input():\n",
    "    rand_vec = torch.randn( 100 ).to(device)\n",
    "    return rand_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_G_batch_vector_input():\n",
    "    rand_vec = torch.randn( (batch_size, 100 ) ).to(device)\n",
    "    return rand_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch_one_hot_rc(batch_size, size):\n",
    "    rand_vec = torch.zeros( (batch_size, num_classes ) ).to(device)\n",
    "    for i in range(batch_size):\n",
    "        random_idx = random.randint(0,size-1)\n",
    "        rand_vec[i, random_idx] = 1.0\n",
    "    return rand_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "list_losses_critic    = []\n",
    "list_losses_generator    = []\n",
    "\n",
    "import tqdm\n",
    "\n",
    "def training_loop(N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt, checkpoint='checkpoint', save_interval: int = None, stop_after: datetime.timedelta = None):\n",
    "    start_time = datetime.datetime.now()\n",
    "    pbar = tqdm.tqdm(range(N_Epochs+1))\n",
    "\n",
    "    for epoch in pbar:\n",
    "        # shuffle dl_train every epoch\n",
    "        # dataset = MyDataset(root='data', normalize=(-1, 1), transform=transforms.Compose([\n",
    "        #     transforms.RandomHorizontalFlip(),\n",
    "        #     transforms.RandomVerticalFlip()\n",
    "        # ]))\n",
    "        # train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.95, 0.05])\n",
    "        dl_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        for xb, yb in dl_train:              ## xb = [batch, 1, 28, 28]\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            # print the memory usage of mps\n",
    "\n",
    "            if xb.shape[0] != batch_size:\n",
    "                # print(f\"skipping batch of size {xb.shape[0]}\")\n",
    "                continue\n",
    "\n",
    "            # xb = xb.reshape(batch_size, 128, width)\n",
    "            # xb = F.pad(xb, (0, 128-width, 0, 0), value=-1) # TODO set to min\n",
    "            yb = yb.repeat(1, 3)\n",
    "            xb = xb.reshape(batch_size, pixels, pixels)\n",
    "            xb = torch.unsqueeze(xb, dim=1)\n",
    "            # pad the image to 140x140\n",
    "            # convert nb [batch, 384] to [batch, -1, 32, channels]\n",
    "\n",
    "            yb_certainty = yb.repeat(channels, pixels, 1, 1).permute(2, 0, 1, 3)#1, 0, 2) # [ batch, x (classes), y, channels ]\n",
    "            # yb_certainty = nb.reshape(batch_size, channels, pixels, -1)\n",
    "            real = torch.cat( (xb, yb_certainty) , dim=3)\n",
    "            # print the real image\n",
    "            # plt.imshow(real[0].squeeze(0).cpu().detach().numpy())\n",
    "\n",
    "            # print the real image TODO this will print nothing because it is normalized to highest number\n",
    "            # plt.imshow(real[0].squeeze(0).cpu().detach().numpy())\n",
    "\n",
    "            for _ in range(5):\n",
    "                noise = torch.cat( (random_G_batch_vector_input(), yb) , dim=1)\n",
    "                fake = G_model( noise )#.detach()\n",
    "                real_pred = D_model( real  ).reshape(-1)\n",
    "                inputs = torch.cat( (fake, yb_certainty) , dim=3)\n",
    "                fake_pred = D_model(  inputs  ).reshape(-1)\n",
    "\n",
    "                fake_loss   = D_loss_fn(D_model, inputs, real, real_pred, fake_pred)\n",
    "                # D_opt.zero_grad()\n",
    "                D_model.zero_grad()\n",
    "                fake_loss.backward(retain_graph=True)\n",
    "                D_opt.step()\n",
    "                \n",
    "            output = D_model( inputs ).reshape(-1)\n",
    "            gen_loss = -torch.mean(output)\n",
    "            G_model.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            G_opt.step()\n",
    "\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            list_losses_generator.append(        gen_loss.cpu().detach().numpy()  )\n",
    "            list_losses_critic.append(        fake_loss.cpu().detach().numpy()  )\n",
    "            D_gen_loss_rnd = np.round(gen_loss.cpu().detach().numpy(), 3)\n",
    "            D_fake_loss_rnd = np.round(fake_loss.cpu().detach().numpy(), 3)\n",
    "\n",
    "            # not rounded anymore :(\n",
    "            message = f\"gen: {D_gen_loss_rnd}; crit: {D_fake_loss_rnd}\"\n",
    "            pbar.set_description(message)\n",
    "            \n",
    "        # draw an image of each class\n",
    "        # place them all on the same figure\n",
    "        if epoch % 100 == 0:\n",
    "            f, axarr = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "            \n",
    "            for i in range(2):\n",
    "                label = dataset[i][1].unsqueeze(0).repeat(1, 3).to(device)\n",
    "\n",
    "                # create noise and make it 2d\n",
    "                noise = random_G_vector_input().unsqueeze(0)\n",
    "                inputs = torch.cat( (noise, label) , dim=1)\n",
    "                output = G_model( inputs ).squeeze(0).cpu()\n",
    "                # convert output (batch, img_size) to (batch, 4, 32, 32)\n",
    "                if channels == 4 or channels == 3:\n",
    "                    # output = output.reshape((-1, 4, pixels, pixels)) # wrong too, lol\n",
    "                    output = output.reshape((-1, channels, pixels, pixels))\n",
    "                    # output = output.reshape((-1, 32, 32))\n",
    "\n",
    "                    img = output.permute(0, 2, 3, 1).detach().numpy()#.reshape(32,32)\n",
    "                elif channels == 1:\n",
    "                    img = output.detach().numpy()\n",
    "\n",
    "                if channels == 4 or channels == 3:\n",
    "                    mode = None\n",
    "                elif channels == 1:\n",
    "                    mode = 'L'\n",
    "\n",
    "                # downscale to 74x74\n",
    "                # TODO is this the best way, seems like the model gives a different output\n",
    "                # 128x128 => 128*128 => 128*128-4 => 1x1x140x39*3 => 140x39\n",
    "                # img = img.reshape(-1)[:-4].reshape(-1, channels, 140, 39*3)\n",
    "                # img = F.interpolate(torch.Tensor(img), size=(140, 39), mode='nearest').squeeze(0).numpy()\n",
    "                # remove the padding\n",
    "                # img = img[:-16].reshape(-1, 140, 39)\n",
    "                # img = img.reshape(-1)[:-4].reshape(-1, 140, 39*3)\n",
    "                img = Image.fromarray((img * 255).astype(np.uint8)[0], mode=mode)\n",
    "                # display the image\n",
    "                axarr[i].imshow(img)\n",
    "\n",
    "                # show the original image\n",
    "                img = dataset[i][0].reshape(-1, pixels, pixels).cpu().detach().numpy()\n",
    "                # img = img[:-4].reshape(-1, 140, 39*3)\n",
    "                # img = F.interpolate(torch.Tensor(img).unsqueeze(0), size=(140, 39), mode='nearest').squeeze(0).numpy()\n",
    "                axarr[i+2].imshow(Image.fromarray((img * 255).astype(np.uint8)[0], mode=mode))\n",
    "            # Note that if showing the plot, plt.show(), shoudl follow plt.savefig(); otherwise, the file image will be blank.\n",
    "            #   - stack overflow person\n",
    "            # save the plot\n",
    "            plt.savefig(f\"{checkpoint}/epoch_{epoch}.png\")\n",
    "            plt.show()\n",
    "        \n",
    "        if save_interval is not None and epoch % save_interval == 0:\n",
    "            torch.save(G_model.state_dict(), f\"{checkpoint}/G_{epoch}.pt\")\n",
    "            torch.save(D_model.state_dict(), f\"{checkpoint}/D_{epoch}.pt\")\n",
    "            # TODO save evrything else\n",
    "        \n",
    "        if stop_after is not None and datetime.datetime.now() > start_time+stop_after:\n",
    "            print(f\"Stopping training because it has been {datetime.datetime.now() - start_time} since {start_time}\")\n",
    "            break\n",
    "\n",
    "    torch.save(G_model.state_dict(), f\"{checkpoint}/G_{epoch}.pt\")\n",
    "    torch.save(D_model.state_dict(), f\"{checkpoint}/D_{epoch}.pt\")\n",
    "    # TODO save evrything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_penatly(critic, real, fake):\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    batch, c, h, w = real.shape\n",
    "    epsilon = torch.rand((batch, 1, 1, 1)).repeat(1, c, h, w).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "\n",
    "    # Take the norm of the gradient\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    grad_norm = gradient.norm(2, dim=1) # L2 norm (euclidean norm)\n",
    "    gradient_penalty = torch.mean((grad_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(D_model, gen_img, real_data, real_pred, fake_pred):\n",
    "    loss =  - (real_pred.mean() - fake_pred.mean()) + 10 * grad_penatly(D_model, real_data, gen_img)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=2, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4, 1, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 1, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 1, 1),\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=2, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size, stride, padding, bias=False\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.critic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): AddChannels()\n",
      "  (1): ConvLayer(\n",
      "    (0): ConvTranspose2d(121, 2048, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (2): ConvLayer(\n",
      "    (0): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (3): ConvLayer(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (4): ConvLayer(\n",
      "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (5): ConvLayer(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (6): ConvLayer(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (7): ConvLayer(\n",
      "    (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (8): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (9): Tanh()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3001 [13:19<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b9e3de5576ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt,\n\u001b[0;32m---> 34\u001b[0;31m     checkpoint='checkpoint', save_interval=100, stop_after=datetime.timedelta(hours=3, minutes=30)   )\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-f3d54d0d853d>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt, checkpoint, save_interval, stop_after)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mG_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mgen_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mG_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fused'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                  found_inf=found_inf)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m          found_inf=found_inf)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "G_model     =  basic_generator(pixels, in_sz=100+7*3, n_channels=channels, n_extra_layers=1)# Generator_Net()\n",
    "print(G_model)\n",
    "# G_model     = Generator_DL_Net()\n",
    "\n",
    "# TODO try 32x32 and doubling kernel, stride\n",
    "\n",
    "# D_model     =    basic_critic(\n",
    "#                     pixels, \n",
    "#                     n_channels=channels, \n",
    "#                     n_extra_layers=1, \n",
    "#                     act_cls=partial(  nn.LeakyReLU, negative_slope=0.2)\n",
    "# )#\n",
    "\n",
    "D_model     = Critic(channels_img=channels, features_d=pixels)\n",
    "\n",
    "# D_model = CriticNet()\n",
    "\n",
    "## D_loss_fn   = nn.CrossEntropyLoss( )  \n",
    "## D_loss_fn   = F.mse_loss\n",
    "\n",
    "D_loss_fn = wasserstein_loss\n",
    "# use a loss function that supports values between -1 and 1\n",
    "# D_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "G_opt       = torch.optim.Adam( G_model.parameters(), lr=learning_rate, betas=(0.0, 0.9) )\n",
    "D_opt       = torch.optim.Adam( D_model.parameters(), lr=learning_rate, betas=(0.0, 0.9) )\n",
    "\n",
    "# move everything to device\n",
    "G_model.to(device)\n",
    "D_model.to(device)\n",
    "# D_loss_fn.to(device)\n",
    "\n",
    "training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt,\n",
    "    checkpoint='checkpoint', save_interval=100, stop_after=datetime.timedelta(hours=3, minutes=30)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_GAN_losses(list_losses_critic, list_losses_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_model     =  basic_generator(pixels, in_sz=100+7*3, n_channels=channels, n_extra_layers=1).to(device)\n",
    "\n",
    "# get the checkpoint with the latest date\n",
    "checkpoint = max([ f for f in os.listdir('checkpoint') if f.startswith('G_') ], key=os.path.getctime)\n",
    "\n",
    "G_model.load_state_dict(torch.load(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        rand = random_G_vector_input().unsqueeze(0)\n",
    "\n",
    "        label = dataset[0][1].to(device).unsqueeze(0).repeat(1, 3)\n",
    "        noise = torch.cat( (rand, label) , dim=1)\n",
    "        fake = G_model.forward( noise ).cpu()\n",
    "        img = fake.squeeze(0).detach().numpy()\n",
    "\n",
    "        # print(img.shape)\n",
    "        # convert img to pil\n",
    "        # img = img.reshape(-1)[:-4].reshape(-1, channels, 140, 39*3)\n",
    "        img = img.reshape(-1).reshape(-1, pixels, pixels)\n",
    "        # img = F.interpolate(torch.Tensor(img), size=(140, 39), mode='nearest').squeeze(0).numpy()\n",
    "        img = Image.fromarray((img * 255).astype(np.uint8)[0], mode='L')\n",
    "        # display the image\n",
    "        # plt.imshow(img)\n",
    "        axarr[i,j].imshow(img)#, interpolation='none', cmap='Blues'\n",
    "\n",
    "        # TODO print comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Anaconda 2020.02)",
   "language": "python",
   "name": "anaconda-2020.02-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
